steps:
  # Initialize with Authentication and Project Setup
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'initialize'
    args:
      - 'config'
      - 'set'
      - 'project'
      - 'api-for-warp-drive'
    env:
      - 'EMOTION_TUNING_PIPELINE=cloudbuild-ci-cttt-emotion-tuning.yaml'
      - 'EMOTION_TUNING_TRIGGER=emotion-tuning-cicd-trigger'

  # Clone Repository
  - name: 'gcr.io/cloud-builders/git'
    id: 'clone'
    args: ['clone', 'https://github.com/YOUR_ORG/api-for-warp-drive.git', '.']

  # Setup Agent Tracking for Build Pipeline
  - name: 'gcr.io/cloud-builders/bash'
    id: 'agent-tracking-setup'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        chmod +x scripts/setup-agent-tracking.sh
        ./scripts/setup-agent-tracking.sh
        export AGENT_ID="CLOUD_BUILD_CI_CTTT"
        source bin/agent-tracking.sh
        log_agent_action "pipeline_start" "Starting CI/CTTT pipeline execution"

  # Install Dependencies
  - name: 'gcr.io/cloud-builders/npm'
    id: 'install'
    args: ['install']

  # Linting
  - name: 'gcr.io/cloud-builders/npm'
    id: 'lint'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "lint_start" "Starting code linting"
        npm run lint
        log_agent_action "lint_complete" "Completed code linting"

  # Code Generator Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'code-generator-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "code_generator_test_start" "Starting code generator tests"

        # Create logs directory if it doesn't exist
        mkdir -p logs

        # Run the code generator tests
        npm run test:code-generator

        # Capture test results
        CODE_GEN_TEST_RESULT=$?

        # Check if directory exists for test artifacts
        mkdir -p test-results/code-generator

        # Copy logs for artifacts
        cp logs/code-generator*.log test-results/code-generator/ || echo "No logs to copy"

        # Report test results
        if [ $CODE_GEN_TEST_RESULT -eq 0 ]; then
          log_agent_action "code_generator_test_complete" "Code generator tests passed successfully"
          echo "Code generator tests passed successfully" > test-results/code-generator/summary.txt
        else
          log_agent_action "code_generator_test_failed" "Code generator tests failed"
          echo "Code generator tests failed" > test-results/code-generator/summary.txt
          # Don't fail the build, just report the failure
        fi

  # Unit Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'unit-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "unit_test_start" "Starting unit tests"
        npm test
        log_agent_action "unit_test_complete" "Completed unit tests"

  # Emotion Tuning Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'emotion-tuning-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "emotion_tuning_test_start" "Starting Emotion Tuning tests"

        # Create test results directory
        mkdir -p test-results/emotion-tuning

        # Run the dedicated emotion tuning test
        npm run test:emotion-tuning

        # Store test result
        EMOTION_TEST_RESULT=$?

        # Create a test summary
        if [ $EMOTION_TEST_RESULT -eq 0 ]; then
          echo "Emotion Tuning tests passed successfully" > test-results/emotion-tuning/summary.txt
          log_agent_action "emotion_tuning_test_complete" "Emotion Tuning tests passed successfully"
        else
          echo "Emotion Tuning tests failed" > test-results/emotion-tuning/summary.txt
          log_agent_action "emotion_tuning_test_failed" "Emotion Tuning tests failed"
          # Don't fail the build, just report the failure
        fi

  # Integration Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'integration-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "integration_test_start" "Starting integration tests"
        # Start local services for testing
        npm run firebase emulators:start --project=api-for-warp-drive & 
        # Wait for emulators to be ready
        sleep 10
        # Run integration tests
        npx jest --testPathPattern=integration
        log_agent_action "integration_test_complete" "Completed integration tests"

  # Build Application
  - name: 'gcr.io/cloud-builders/npm'
    id: 'build'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "build_start" "Starting application build"
        npm run build
        log_agent_action "build_complete" "Completed application build"

  # Docker Image Build
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-build'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "docker_build_start" "Starting Docker image build"
        docker build -t gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA -t gcr.io/api-for-warp-drive/aixtiv-cli:latest .
        log_agent_action "docker_build_complete" "Completed Docker image build"

  # Push Docker Image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-push'
    args: ['push', 'gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA']

  # Security Scanning
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'security-scan'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "security_scan_start" "Starting security scanning"
        # Use Container Analysis API to scan the Docker image
        gcloud container images describe gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA \
          --format='value(discovery.analysisStatus)'

        # Run npm audit for package vulnerabilities
        npm audit --audit-level=high
        log_agent_action "security_scan_complete" "Completed security scanning"

  # Deploy to Staging (GKE)
  - name: 'gcr.io/cloud-builders/kubectl'
    id: 'deploy-staging'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Connect to GKE cluster
        gcloud container clusters get-credentials private-cluster-auto --zone us-west1-b --project api-for-warp-drive

        source bin/agent-tracking.sh
        log_agent_action "staging_deploy_start" "Starting deployment to staging"

        # Update deployment YAML with new image
        sed -i "s|gcr.io/api-for-warp-drive/aixtiv-cli:.*|gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA|g" infrastructure/staging/deployment.yaml

        # Apply updated deployment
        kubectl apply -f infrastructure/staging/deployment.yaml
        kubectl apply -f infrastructure/staging/service.yaml
        log_agent_action "staging_deploy_complete" "Completed deployment to staging"
    env:
      - 'CLOUDSDK_COMPUTE_ZONE=us-west1-b'
      - 'CLOUDSDK_CONTAINER_CLUSTER=private-cluster-auto'

  # Test Staging Deployment
  - name: 'gcr.io/cloud-builders/curl'
    id: 'test-staging'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "staging_test_start" "Starting staging environment tests"

        # Wait for deployment to complete
        sleep 30

        # Test API endpoints
        STAGING_IP=$(kubectl get svc aixtiv-cli-staging -n anthology-ai-staging -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        HEALTH_CHECK=$(curl -s -o /dev/null -w "%{http_code}" http://$STAGING_IP/health)

        if [ "$HEALTH_CHECK" -eq 200 ]; then
          echo "Staging health check passed: $HEALTH_CHECK"
          log_agent_action "staging_test_complete" "Staging environment tests successful"
        else
          echo "Staging health check failed: $HEALTH_CHECK"
          log_agent_action "staging_test_failed" "Staging environment tests failed"
          exit 1
        fi

  # Coaching2100 Domain Autoscale Management
  - name: 'gcr.io/cloud-builders/python'
    id: 'domain-autoscale'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        export ORGANIZATION="Coaching2100"
        log_agent_action "coaching2100_domain_autoscale_start" "Starting Coaching2100 domain autoscale management"

        # Install required dependencies
        pip install -r requirements.txt

        # Configure GoDaddy API credentials from Secret Manager
        mkdir -p ~/.aixtiv
        gcloud secrets versions access latest --secret=coaching2100-godaddy-api-credentials > ~/.aixtiv/godaddy-api-key.json
        chmod 600 ~/.aixtiv/godaddy-api-key.json

        # Configure Firebase
        npm install -g firebase-tools
        # Authenticate with Firebase using service account
        firebase use api-for-warp-drive --token "$(gcloud auth print-access-token)"

        # Load Coaching2100 domain configuration
        if [ ! -f "config/domain/coaching2100-domain-config.json" ]; then
          echo "Creating Coaching2100 domain configuration..."
          mkdir -p config/domain
          cat > config/domain/coaching2100-domain-config.json << 'ENDCONFIG'
{
  "organization": "Coaching2100",
  "organizationDisplayName": "Coaching 2100",
  "domainAccountId": "coaching2100",
  "defaultFirebaseProject": "api-for-warp-drive",
  "serviceAccount": "drlucyautomation@api-for-warp-drive.iam.gserviceaccount.com",
  "domainFamilies": {
    "character": {
      "pattern": "^(dr|professor|mr|mrs|ms|coach)",
      "project": "anthology-ai",
      "description": "Character domains for Coaching 2100 agents"
    },
    "aixtiv": {
      "pattern": "^(aixtiv|symphony)",
      "project": "api-for-warp-drive",
      "description": "Aixtiv platform domains"
    },
    "learning": {
      "pattern": "^(learn|tutor|course|class|training)",
      "project": "learning-pathway",
      "description": "Learning and educational domains"
    },
    "brand": {
      "pattern": "^(coaching2100|c2100|anthology)",
      "project": "brand-site",
      "description": "Coaching 2100 brand domains"
    },
    "flight": {
      "pattern": "^(flight|fly|pilot|aviation)",
      "project": "flight-school",
      "description": "Flight school domains"
    },
    "default": {
      "pattern": ".*",
      "project": "api-for-warp-drive",
      "description": "Default domain family for unmatched domains"
    }
  },
  "domainsFile": "domains/coaching2100-domains.txt",
  "cacheLifetime": 86400,
  "apiRateLimit": 60,
  "dnsSettings": {
    "defaultTTL": 3600,
    "aRecords": ["151.101.1.195", "151.101.65.195"],
    "cnameValue": "coaching2100.github.io"
  },
  "verificationSettings": {
    "retryAttempts": 3,
    "verificationTimeout": 300,
    "dnsCheckInterval": 60
  }
}
ENDCONFIG
        fi

        # Run domain autoscale integration
        python automation/domain-autoscale-integration.py \
          --project-id $PROJECT_ID \
          --agent-id "COACHING2100_DOMAIN_AUTOMATION" \
          --phase full

        log_agent_action "coaching2100_domain_autoscale_complete" "Completed Coaching2100 domain autoscale management"
  # Execute Continuous Training (if changes detected in ML models)
  - name: 'gcr.io/cloud-builders/python'
    id: 'continuous-training'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "training_analysis_start" "Analyzing for training requirements"

        # Check if this build needs model retraining
        NEEDS_TRAINING=$(python -c "
        import os, glob
        model_files = glob.glob('src/models/**/*.py', recursive=True)
        last_commit = os.environ.get('COMMIT_SHA')
        print('true' if model_files else 'false')
        ")

        if [ "$NEEDS_TRAINING" == "true" ]; then
          log_agent_action "training_start" "Starting model training"
          python -m automation.runner --train-models
          log_agent_action "training_complete" "Completed model training"
        else
          log_agent_action "training_skipped" "Model training not required"
        fi

  # Speaker Recognition Test and Training
  - name: 'gcr.io/cloud-builders/python'
    id: 'speaker-recognition-pipeline'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "speaker_recognition_start" "Starting speaker recognition pipeline"

        # Test speaker recognition components
        npm run test -- -t "speaker-recognition"

        # Check if speaker recognition models need training
        SPEAKER_CHANGES=$(git diff --name-only HEAD~1 HEAD | grep -E 'speaker-recognition|speech/speaker')

        if [ -n "$SPEAKER_CHANGES" ]; then
          log_agent_action "speaker_training_start" "Starting speaker recognition model training"

          # Submit AI Platform training job
          gcloud ai-platform jobs submit training speaker_recognition_${BUILD_ID} \
            --region=us-west1 \
            --master-image-uri=gcr.io/api-for-warp-drive/speaker-training:latest \
            --config=training/speaker-recognition-config.yaml

          log_agent_action "speaker_training_submitted" "Speaker recognition training job submitted"
        else
          log_agent_action "speaker_training_skipped" "Speaker recognition training not required"
        fi

        # Deploy speaker recognition monitoring dashboard
        gcloud monitoring dashboards create \
          --config-from-file=monitoring/speaker-recognition-dashboard.json

        log_agent_action "speaker_recognition_complete" "Speaker recognition pipeline completed"

  # Create GitHub Release (for successful builds)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'github-release'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "release_creation_start" "Starting GitHub release creation"

        # Install GitHub CLI
        apt-get update && apt-get install -y gh

        # Create a new release tag
        VERSION=$(cat package.json | grep version | head -1 | awk -F: '{ print $2 }' | sed 's/[\",]//g' | tr -d '[:space:]')
        RELEASE_TAG="v$VERSION-$(date +%Y%m%d-%H%M%S)"

        # Create release
        gh auth login --with-token < /secrets/github-token
        gh release create $RELEASE_TAG \
          --title "Release $RELEASE_TAG" \
          --notes "Automated release created by CI/CD pipeline"

        log_agent_action "release_creation_complete" "Completed GitHub release creation"

  # Update Monitoring Dashboard
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'update-monitoring'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "monitoring_update_start" "Updating monitoring configuration"

        # Update monitoring configuration
        gcloud monitoring dashboards create \
          --config-from-file=monitoring/dashboard.json
          
        log_agent_action "monitoring_update_complete" "Monitoring configuration updated"

  # Emotion Tuning Integration
  - name: 'gcr.io/cloud-builders/node'
    id: 'emotion-tuning-integration'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "emotion_tuning_integration_start" "Starting Emotion Tuning integration"

        # Check if Emotion Tuning files changed in this commit
        EMOTION_TUNING_CHANGES=$(git diff --name-only HEAD~1 HEAD | grep -E 'emotion-tuning|copilot/emotion|speech/')

        if [ -n "$EMOTION_TUNING_CHANGES" ]; then
          log_agent_action "emotion_tuning_changes_detected" "Emotion Tuning changes detected"

          # Run the integration script
          node cicd/emotion-tuning-integration.js --environment=production

          # Trigger the Emotion Tuning specific pipeline
          gcloud builds triggers run ${EMOTION_TUNING_TRIGGER} --branch=main

          log_agent_action "emotion_tuning_pipeline_triggered" "Emotion Tuning CI/CD pipeline triggered"
        else
          log_agent_action "emotion_tuning_unchanged" "No changes to Emotion Tuning system"
        fi

        log_agent_action "emotion_tuning_integration_complete" "Emotion Tuning integration completed"

  # Notify Pipeline Completion
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'notify-completion'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "pipeline_complete" "CI/CTTT pipeline completed successfully"

        # Create deployment record in Firestore
        gcloud firestore documents create projects/api-for-warp-drive/databases/(default)/documents/deployments/$(date +%Y%m%d%H%M%S) \
          --fields="status=SUCCESS,timestamp=$(date +%s),agent=DR_CLAUDE_AUTOMATION,version=$COMMIT_SHA,environment=staging"

        echo "ðŸš€ CI/CTTT Pipeline completed successfully!"
        echo "âœ… Staging deployment: COMPLETE"
        echo "âœ… Coaching2100 domain autoscale management: COMPLETE"
        echo "âœ… Emotion Tuning integration: COMPLETE"
        echo "âœ… Artifacts available at: gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA"
        echo "âœ… Agent tracking logs: Available in BigQuery"

timeout: '3600s' # 60 minutes
options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
  env:
    - 'AGENT_ID=DR_CLAUDE_AUTOMATION'

artifacts:
  objects:
    location: 'gs://api-for-warp-drive-artifacts/builds/$BUILD_ID/'
    paths: [
      'test-results/**/*',
      'coverage/**/*',
      'dist/**/*',
      'logs/code-generator*.log',
      'src/services/emotion-tuning/**/*',
      'commands/copilot/emotion.js',
      'test/emotion-tuning-test.js',
      'cicd/emotion-tuning-integration.js'
    ]

serviceAccount: 'drlucyautomation@api-for-warp-drive.iam.gserviceaccount.com'
