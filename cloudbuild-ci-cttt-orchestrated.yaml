steps:
  # Initialize with Authentication and Project Setup
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'initialize'
    args:
      - 'config'
      - 'set'
      - 'project'
      - 'api-for-warp-drive'

  # Clone Repository
  - name: 'gcr.io/cloud-builders/git'
    id: 'clone'
    args: ['clone', 'https://github.com/AI-Publishing-International-LLP-UK/AIXTIV-SYMPHONY.git']

  # Setup Agent Tracking for Build Pipeline
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'agent-tracking-setup'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        chmod +x scripts/setup-agent-tracking.sh
        ./scripts/setup-agent-tracking.sh
        export AGENT_ID="CLOUD_BUILD_CI_CTTT"
        source bin/agent-tracking.sh
        log_agent_action "pipeline_start" "Starting CI/CTTT pipeline with Claude orchestration"

  # Fetch Claude Orchestration Credentials
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'fetch-secrets'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Get API keys from Secret Manager
        gcloud secrets versions access latest --secret="new-admin-anthropic" > /workspace/anthropic_key.txt
        gcloud secrets versions access latest --secret="pineconeconnect" > /workspace/pinecone_key.txt
        gcloud secrets versions access latest --secret="langchain03_api_for_warp_drive" > /workspace/langchain_key.txt
        
        # Export as environment variables for later steps
        echo "export ANTHROPIC_API_KEY=$(cat /workspace/anthropic_key.txt)" >> /workspace/env_vars.sh
        echo "export PINECONE_API_KEY=$(cat /workspace/pinecone_key.txt)" >> /workspace/pinecone_key.txt
        echo "export LANGCHAIN_API_KEY=$(cat /workspace/langchain_key.txt)" >> /workspace/env_vars.sh
        
        # Set permissions
        chmod 600 /workspace/anthropic_key.txt /workspace/pinecone_key.txt /workspace/langchain_key.txt /workspace/env_vars.sh
        
        source bin/agent-tracking.sh
        log_agent_action "credentials_fetch" "Retrieved API credentials from Secret Manager"

  # Install Dependencies
  - name: 'gcr.io/cloud-builders/npm'
    id: 'install'
    args: ['install']

  # Setup Claude Orchestration 
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'setup-claude-orchestration'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        
        log_agent_action "claude_orchestration_setup" "Setting up Claude orchestration with auto-scaling"
        
        # Initialize the Pinecone vector database connection for Claude
        python -c "
        import os
        import sys
        from src.services.secrets.secret_manager import SecretManager
        from src.services.secrets.provider_factory import ProviderFactory
        
        # Initialize services
        secret_manager = SecretManager()
        provider_factory = ProviderFactory()
        
        # Set API keys from environment 
        os.environ['PINECONE_API_KEY'] = open('/workspace/pinecone_key.txt').read().strip()
        os.environ['ANTHROPIC_API_KEY'] = open('/workspace/anthropic_key.txt').read().strip()
        
        # Initialize the connections
        pinecone = provider_factory.createPineconeClient()
        anthropic = provider_factory.createAnthropicClient()
        
        # Setup the indices needed for the pipeline
        from src.functions.pinecone_integration_updated import createIndexIfNotExists
        createIndexIfNotExists('cttt-pipeline-artifacts')
        createIndexIfNotExists('claude-context-definitions')
        createIndexIfNotExists('claude-workflow-templates')
        
        print('Claude orchestration setup complete')
        "
        
        log_agent_action "claude_orchestration_ready" "Claude orchestration with auto-scaling ready"

  # Run Pipeline with Claude Orchestration
  - name: 'python:3.9'
    id: 'run-cttt-pipeline'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        
        log_agent_action "cttt_pipeline_start" "Starting CTTT pipeline with Claude orchestration"
        
        # Install Python dependencies
        pip install firebase-admin google-cloud-firestore google-cloud-secret-manager anthropic pinecone-client pydantic
        
        # Add agent orchestration parameters to pipeline config
        cat > orchestration_config.json << EOL
        {
          "claude_orchestration": {
            "enabled": true,
            "auto_scaling": true,
            "max_parallel_tasks": 5,
            "priority_levels": ["high", "medium", "low"],
            "vector_storage": {
              "enabled": true,
              "index_name": "cttt-pipeline-artifacts"
            },
            "agents": {
              "dr_memoria": {
                "enabled": true,
                "vector_index": "memoria-linkedin-content"
              },
              "dr_match": {
                "enabled": true,
                "vector_index": "match-linkedin-profiles"
              },
              "dr_lucy": {
                "enabled": true,
                "vector_index": "lucy-github-repos"
              }
            }
          }
        }
        EOL
        
        # Execute the CTTT pipeline with orchestration
        python automation/cttt-pipeline.py --project-id="api-for-warp-drive" --agent-id="DR_CLAUDE_ORCHESTRATION" --config=orchestration_config.json
        
        # Store orchestration results in Pinecone for future reference
        python -c "
        import os
        import json
        import time
        from datetime import datetime
        from src.functions.pinecone_integration_updated import storeInPinecone
        
        # Load the pipeline results
        latest_results_file = max(list(path for path in os.listdir('reports/cttt') if path.startswith('pipeline-results-')), key=os.path.getctime)
        with open(f'reports/cttt/{latest_results_file}', 'r') as f:
            results = json.load(f)
        
        # Store in Pinecone
        item = {
            'id': f'pipeline-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}',
            'text': json.dumps(results),
            'metadata': {
                'pipelineId': os.environ.get('BUILD_ID', 'local'),
                'timestamp': int(time.time()),
                'success': all(phase.get('success', False) for phase in results.values() if isinstance(phase, dict)),
                'agent': 'DR_CLAUDE_ORCHESTRATION'
            }
        }
        
        storeInPinecone('cttt-pipeline-artifacts', [item])
        print(f'Pipeline results stored in Pinecone: {item[\"id\"]}')
        "
        
        log_agent_action "cttt_pipeline_complete" "Completed CTTT pipeline with Claude orchestration"

  # Linting
  - name: 'gcr.io/cloud-builders/npm'
    id: 'lint'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "lint_start" "Starting code linting"
        npm run lint
        log_agent_action "lint_complete" "Completed code linting"

  # Unit Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'unit-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "unit_test_start" "Starting unit tests"
        npm test
        log_agent_action "unit_test_complete" "Completed unit tests"

  # Integration Tests
  - name: 'gcr.io/cloud-builders/npm'
    id: 'integration-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "integration_test_start" "Starting integration tests"
        # Start local services for testing
        npm run firebase emulators:start --project=api-for-warp-drive & 
        # Wait for emulators to be ready
        sleep 10
        # Run integration tests
        npx jest --testPathPattern=integration
        log_agent_action "integration_test_complete" "Completed integration tests"

  # Build Application
  - name: 'gcr.io/cloud-builders/npm'
    id: 'build'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "build_start" "Starting application build"
        npm run build
        log_agent_action "build_complete" "Completed application build"

  # Docker Image Build with Agent Integration
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-build'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        log_agent_action "docker_build_start" "Starting Docker image build with agent integration"
        
        # Set a default COMMIT_SHA if it's not defined
        COMMIT_SHA="${COMMIT_SHA:-$(date +%Y%m%d-%H%M%S)}"
        
        # Create Docker build arguments file with agent configurations
        cat > docker-build-args.env << EOF
        BUILD_ID=${BUILD_ID}
        COMMIT_SHA=${COMMIT_SHA}
        AGENT_ID=DR_CLAUDE_ORCHESTRATION
        ENABLE_AGENT_INTEGRATION=true
        ENABLE_PINECONE=true
        ENABLE_LINKEDIN=true
        EOF
        
        # Build Docker image with agent integrations enabled
        docker build --build-arg-file=docker-build-args.env -t gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA .
        log_agent_action "docker_build_complete" "Completed Docker image build with agent integration"

  # Push Docker Image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-push'
    entrypoint: 'bash'
    args: 
      - '-c'
      - |
        # Set a default COMMIT_SHA if it's not defined
        COMMIT_SHA="${COMMIT_SHA:-$(date +%Y%m%d-%H%M%S)}"
        docker push gcr.io/api-for-warp-drive/aixtiv-cli:$COMMIT_SHA

  # Security Scanning
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'security-scan'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "security_scan_start" "Starting security scanning"
        # Use Container Analysis API to scan the Docker image
        gcloud container images describe gcr.io/api-for-warp-drive/aixtiv-cli:$$COMMIT_SHA \
          --format='value(discovery.analysisStatus)'
        
        # Run npm audit for package vulnerabilities
        npm audit --audit-level=high
        log_agent_action "security_scan_complete" "Completed security scanning"

  # Deploy to Staging (GKE) with Auto-scaling Configuration
  - name: 'gcr.io/cloud-builders/kubectl'
    id: 'deploy-staging'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Connect to GKE cluster
        gcloud container clusters get-credentials private-cluster-auto --zone us-west1-b --project api-for-warp-drive
        
        source bin/agent-tracking.sh
        log_agent_action "staging_deploy_start" "Starting deployment to staging with auto-scaling"
        
        # Update deployment YAML with new image and auto-scaling
        sed -i "s|gcr.io/api-for-warp-drive/aixtiv-cli:.*|gcr.io/api-for-warp-drive/aixtiv-cli:$$COMMIT_SHA|g" infrastructure/staging/deployment.yaml
        
        # Add Claude orchestration environment variables
        cat > claude-orchestration-patch.yaml << EOF
        spec:
          template:
            spec:
              containers:
              - name: aixtiv-cli
                env:
                - name: ENABLE_CLAUDE_ORCHESTRATION
                  value: "true"
                - name: CLAUDE_AUTO_SCALING
                  value: "true"
                - name: CLAUDE_MAX_PARALLEL_TASKS
                  value: "5"
                - name: PINECONE_ENABLED
                  value: "true"
        EOF
        
        # Apply the patch to enable Claude orchestration
        kubectl patch -f infrastructure/staging/deployment.yaml --patch "$(cat claude-orchestration-patch.yaml)"
        
        # Create horizontal pod autoscaler for dynamic scaling
        cat > hpa.yaml << EOF
        apiVersion: autoscaling/v2
        kind: HorizontalPodAutoscaler
        metadata:
          name: aixtiv-cli-hpa
          namespace: anthology-ai-staging
        spec:
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: aixtiv-cli-staging
          minReplicas: 2
          maxReplicas: 10
          metrics:
          - type: Resource
            resource:
              name: cpu
              target:
                type: Utilization
                averageUtilization: 50
          - type: Resource
            resource:
              name: memory
              target:
                type: Utilization
                averageUtilization: 60
        EOF
        
        # Apply updated deployment, service, and autoscaling
        kubectl apply -f infrastructure/staging/deployment.yaml
        kubectl apply -f infrastructure/staging/service.yaml
        kubectl apply -f hpa.yaml
        log_agent_action "staging_deploy_complete" "Completed deployment to staging with auto-scaling"
    env:
      - 'CLOUDSDK_COMPUTE_ZONE=us-west1-b'
      - 'CLOUDSDK_CONTAINER_CLUSTER=private-cluster-auto'

  # Test Staging Deployment
  - name: 'gcr.io/cloud-builders/curl'
    id: 'test-staging'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "staging_test_start" "Starting staging environment tests"
        
        # Wait for deployment to complete
        sleep 30
        
        # Test API endpoints
        STAGING_IP=$$(kubectl get svc aixtiv-cli-staging -n anthology-ai-staging -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        HEALTH_CHECK=$$(curl -s -o /dev/null -w "%{http_code}" http://$$STAGING_IP/health)
        
        if [ "$$HEALTH_CHECK" -eq 200 ]; then
          echo "Staging health check passed: $$HEALTH_CHECK"
          log_agent_action "staging_test_complete" "Staging environment tests successful"
        else
          echo "Staging health check failed: $$HEALTH_CHECK"
          log_agent_action "staging_test_failed" "Staging environment tests failed"
          exit 1
        fi

  # Execute Continuous Training with Claude Supervision
  - name: 'gcr.io/cloud-builders/python'
    id: 'continuous-training'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        log_agent_action "training_analysis_start" "Analyzing for training requirements with Claude supervision"
        
        # Check if this build needs model retraining
        NEEDS_TRAINING=$$(python -c "
        import os, glob
        model_files = glob.glob('src/models/**/*.py', recursive=True)
        last_commit = os.environ.get('COMMIT_SHA')
        print('true' if model_files else 'false')
        ")
        
        if [ "$$NEEDS_TRAINING" == "true" ]; then
          log_agent_action "training_start" "Starting model training with Claude supervision"
          
          # Create Claude supervision context
          python -c "
          import anthropic
          import json
          import os
          
          client = anthropic.Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
          
          # Create a system prompt for Claude to supervise training
          system_prompt = '''
          You are Claude, supervising a machine learning training pipeline.
          Your task is to analyze training metrics, detect anomalies, and provide
          guidance on improving model performance.
          
          The training will report metrics that you should analyze for:
          1. Signs of overfitting or underfitting
          2. Learning rate issues
          3. Feature importance insights
          4. Suggestions for hyperparameter tuning
          '''
          
          # Initialize the Claude session
          message = client.messages.create(
              model='claude-3-opus-20240229',
              max_tokens=2000,
              system=system_prompt,
              messages=[
                  {'role': 'user', 'content': 'Training is about to begin. Please prepare to receive metrics.'}
              ]
          )
          
          # Save the Claude thread ID for future interactions
          with open('/workspace/claude_thread.json', 'w') as f:
              json.dump({'thread_id': message.id}, f)
          
          print('Claude supervision initialized')
          "
          
          # Run the training with Claude supervision
          python -m automation.runner --train-models --with-claude-supervision
          
          log_agent_action "training_complete" "Completed model training with Claude supervision"
        else
          log_agent_action "training_skipped" "Model training not required"
        fi

  # Create GitHub Release with Agent Context
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'github-release'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        log_agent_action "release_creation_start" "Starting GitHub release creation with agent context"
        
        # Install GitHub CLI
        apt-get update && apt-get install -y gh
        
        # Create a new release tag
        VERSION=$$(cat package.json | grep version | head -1 | awk -F: '{ print $2 }' | sed 's/[\",]//g' | tr -d '[:space:]')
        RELEASE_TAG="v$$VERSION-$$(date +%Y%m%d-%H%M%S)"
        
        # Generate release notes with Claude insight
        python -c "
        import anthropic
        import json
        import os
        import subprocess
        
        # Get Claude's API key
        client = anthropic.Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
        
        # Get git log since last tag
        git_log = subprocess.run(['git', 'log', '--pretty=format:%s', '-n', '20'], 
                                capture_output=True, text=True).stdout
        
        # Ask Claude to generate insights
        message = client.messages.create(
            model='claude-3-opus-20240229',
            max_tokens=1000,
            system='You are an expert at creating insightful release notes from Git commit messages.',
            messages=[
                {'role': 'user', 'content': f'''
                These are the recent commits:
                
                {git_log}
                
                Please create concise, professional release notes that highlight:
                1. Key features added
                2. Improvements made
                3. Bugs fixed
                
                Format it in Markdown syntax.
                '''}
            ]
        )
        
        # Save Claude's release notes
        with open('/workspace/release_notes.md', 'w') as f:
            f.write(message.content[0].text)
        
        print('Release notes generated by Claude')
        "
        
        # Create release with Claude-generated notes
        gh auth login --with-token < /secrets/github-token
        gh release create $$RELEASE_TAG \
          --title "Release $$RELEASE_TAG" \
          --notes-file /workspace/release_notes.md
        
        log_agent_action "release_creation_complete" "Completed GitHub release creation with agent context"

  # Update Monitoring Dashboard with Agent Metrics
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'update-monitoring'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        log_agent_action "monitoring_update_start" "Updating monitoring configuration with agent metrics"
        
        # Create agent monitoring dashboard
        cat > agent_monitoring_dashboard.json << EOF
        {
          "displayName": "Claude Orchestration Dashboard",
          "gridLayout": {
            "columns": "2",
            "widgets": [
              {
                "title": "Claude Orchestration CPU Usage",
                "xyChart": {
                  "dataSets": [{
                    "timeSeriesQuery": {
                      "timeSeriesFilter": {
                        "filter": "metric.type=\"kubernetes.io/container/cpu/utilization\" resource.type=\"k8s_container\" resource.label.\"container_name\"=\"aixtiv-cli\" metadata.user_labels.\"component\"=\"claude-orchestration\"",
                        "aggregation": {
                          "alignmentPeriod": "60s",
                          "perSeriesAligner": "ALIGN_MEAN"
                        }
                      }
                    },
                    "plotType": "LINE"
                  }]
                }
              },
              {
                "title": "Claude Orchestration Memory Usage",
                "xyChart": {
                  "dataSets": [{
                    "timeSeriesQuery": {
                      "timeSeriesFilter": {
                        "filter": "metric.type=\"kubernetes.io/container/memory/used_bytes\" resource.type=\"k8s_container\" resource.label.\"container_name\"=\"aixtiv-cli\" metadata.user_labels.\"component\"=\"claude-orchestration\"",
                        "aggregation": {
                          "alignmentPeriod": "60s",
                          "perSeriesAligner": "ALIGN_MEAN"
                        }
                      }
                    },
                    "plotType": "LINE"
                  }]
                }
              },
              {
                "title": "Claude API Calls",
                "xyChart": {
                  "dataSets": [{
                    "timeSeriesQuery": {
                      "timeSeriesFilter": {
                        "filter": "metric.type=\"custom.googleapis.com/anthropic/api_calls\" resource.type=\"global\"",
                        "aggregation": {
                          "alignmentPeriod": "60s",
                          "perSeriesAligner": "ALIGN_SUM"
                        }
                      }
                    },
                    "plotType": "LINE"
                  }]
                }
              },
              {
                "title": "Pinecone Operations",
                "xyChart": {
                  "dataSets": [{
                    "timeSeriesQuery": {
                      "timeSeriesFilter": {
                        "filter": "metric.type=\"custom.googleapis.com/pinecone/operations\" resource.type=\"global\"",
                        "aggregation": {
                          "alignmentPeriod": "60s",
                          "perSeriesAligner": "ALIGN_SUM"
                        }
                      }
                    },
                    "plotType": "LINE"
                  }]
                }
              }
            ]
          }
        }
        EOF
        
        # Update monitoring configuration
        gcloud monitoring dashboards create \
          --config-from-file=agent_monitoring_dashboard.json
          
        log_agent_action "monitoring_update_complete" "Monitoring configuration updated with agent metrics"

  # Notify Pipeline Completion with Claude Summary
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'notify-completion'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        source bin/agent-tracking.sh
        source /workspace/env_vars.sh
        log_agent_action "pipeline_complete" "CI/CTTT pipeline with Claude orchestration completed"
        
        # Generate Claude summary of the pipeline run
        python -c "
        import anthropic
        import json
        import os
        import glob
        from datetime import datetime
        
        # Find the latest pipeline results
        latest_results_file = max(glob.glob('reports/cttt/pipeline-results-*.json'), key=os.path.getctime)
        with open(latest_results_file, 'r') as f:
            results = json.load(f)
        
        # Get Claude's API key
        client = anthropic.Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
        
        # Ask Claude to generate a summary
        message = client.messages.create(
            model='claude-3-opus-20240229',
            max_tokens=1000,
            system='You are a CI/CD pipeline analyst who creates concise, informative summaries of pipeline runs.',
            messages=[
                {'role': 'user', 'content': f'''
                Here are the results of our CI/CTTT pipeline run:
                
                {json.dumps(results, indent=2)}
                
                Please provide a concise summary of:
                1. Overall status and success rate
                2. Key metrics across testing, training, and tuning phases
                3. Any issues or recommendations
                4. Next steps for the team
                
                Format it as a short report suitable for a Slack message.
                '''}
            ]
        )
        
        # Save Claude's summary
        with open('/workspace/pipeline_summary.md', 'w') as f:
            f.write(message.content[0].text)
        
        print('Pipeline summary generated by Claude')
        "
        
        # Create deployment record in Firestore
        gcloud firestore documents create projects/api-for-warp-drive/databases/(default)/documents/deployments/$$(date +%Y%m%d%H%M%S) \
          --fields="status=SUCCESS,timestamp=$$(date +%s),agent=DR_CLAUDE_ORCHESTRATION,version=$$COMMIT_SHA,environment=staging,orchestrated=true"
        
        echo "ðŸš€ CI/CTTT Pipeline with Claude orchestration completed successfully!"
        echo "âœ… Staging deployment: COMPLETE with auto-scaling enabled"
        echo "âœ… Artifacts available at: gcr.io/api-for-warp-drive/aixtiv-cli:$$COMMIT_SHA"
        echo "âœ… Agent tracking logs: Available in BigQuery"
        echo ""
        echo "ðŸ“‹ Claude Pipeline Summary:"
        cat /workspace/pipeline_summary.md

timeout: "3600s"  # 60 minutes
options:
  machineType: 'E2_HIGHCPU_8'
  logging: CLOUD_LOGGING_ONLY
  env:
    - 'AGENT_ID=DR_CLAUDE_ORCHESTRATION'

artifacts:
  objects:
    location: 'gs://api-for-warp-drive-artifacts/builds/$BUILD_ID/'
    paths: ['test-results/**/*', 'coverage/**/*', 'dist/**/*', '/workspace/pipeline_summary.md', '/workspace/release_notes.md']

serviceAccount: 'projects/api-for-warp-drive/serviceAccounts/drlucyautomation@api-for-warp-drive.iam.gserviceaccount.com'